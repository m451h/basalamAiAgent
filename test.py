import os
from operator import itemgetter
from basalam_search import search_basalam

from langchain.chat_models import init_chat_model
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain import hub

from dotenv import load_dotenv

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ .env
load_dotenv()

# Ø³Øª Ú©Ø±Ø¯Ù† API config Ø§Ø² .env
os.environ["OPENAI_API_KEY"] = os.getenv("AVALAI_API_KEY")
os.environ["OPENAI_API_BASE"] = os.getenv("AVALAI_API_BASE")


# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù¾Ø±Ø§Ù…Ù¾Øª
with open("prompts/base.txt", "r", encoding="utf-8") as f:
    system_prompt = f.read()

# Ù…Ø¯Ù„ LLM Ùˆ Ø§Ø¨Ø²Ø§Ø± Ø¬Ø³ØªØ¬Ùˆ
llm = init_chat_model("gpt-4o-mini", model_provider="openai")
llm_with_tools = llm.bind_tools([search_basalam])

# Ø³Ø§Ø®Øª Ø¹Ø§Ù…Ù„ Ù‡ÙˆØ´Ù…Ù†Ø¯
prompt = hub.pull("hwchase17/openai-tools-agent")
prompt.messages[0].prompt.template = system_prompt

tools = [search_basalam]
agent = create_tool_calling_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
'''
# Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø§Ø±Ø¨Ø±
#user_input = "Ø¹Ø³Ù„ Ø·Ø¨ÛŒØ¹ÛŒ Ø¨Ø§ Ù‚ÛŒÙ…Øª Ù…Ù†Ø§Ø³Ø¨ Ùˆ Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§"
user_input = input("Ù„Ø·ÙØ§Ù‹ Ø¹Ø¨Ø§Ø±Øª Ø¬Ø³ØªØ¬Ùˆ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯: ")
response = agent_executor.invoke({"input": user_input})

# Ú†Ø§Ù¾ Ø®Ø±ÙˆØ¬ÛŒ
print("âœ… Ù¾Ø§Ø³Ø® Ø¯Ø³ØªÛŒØ§Ø±:\n")
print(response["output"])
'''
while True:
    user_input = input("ğŸŸ¢ Ø´Ù…Ø§: ")
    if user_input.strip().lower() in ["Ø®Ø±ÙˆØ¬", "exit", "quit"]:
        break
    response = agent_executor.invoke({"input": user_input})
    print("\nğŸ¤– Ø¯Ø³ØªÛŒØ§Ø±:", response["output"])
    print("--------------------------------------------------")